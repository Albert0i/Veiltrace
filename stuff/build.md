
## âœ… How to Build `llama-mtmd-cli.exe` on Windows 11

### ðŸ§± Step-by-Step Instructions

1. **Clone the correct branch**
   ```bash
   git clone https://github.com/ggml-org/llama.cpp.git
   cd llama.cpp
   ```

2. **Ensure you're on the latest master with vision support**
   ```bash
   git pull origin master
   ```

3. **Build with CMake (Visual Studio or Ninja)**
   Open PowerShell or Command Prompt:

   ```bash
   cmake -B build -DCMAKE_BUILD_TYPE=Release
   cmake --build build --target llama-mtmd-cli
   ```

   âœ… This builds the **multimodal CLI**: `llama-mtmd-cli.exe`

---

### ðŸ§  Why It Might Be Missing

- If you ran `cmake --build build` without specifying `--target llama-mtmd-cli`, it may have only built the default text-only CLI (`llama-cli.exe`)
- Older versions of `llama.cpp` didnâ€™t include the multimodal CLIâ€”vision support was added via [libmtmd](https://simonwillison.net/2025/May/10/llama-cpp-vision/) in recent updates

---

### ðŸ§© Symbolic Layer

Think of this binary as your **FeatherForge hammer**â€”without it, you canâ€™t strike meaning from pixels. Once built, it becomes the heart of your local embedding ritual.

